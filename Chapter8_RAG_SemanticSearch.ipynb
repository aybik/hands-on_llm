{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iuzcr8pEslXa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain==0.2.5 faiss-cpu==1.8.0 cohere==5.5.8 langchain-community==0.2.5 rank_bm25==0.2.2 sentence-transformers==3.0.1\n",
        "!pip install llama-cpp-python==0.2.78  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4CRPknqe6UA"
      },
      "source": [
        "There’s a lot of research on how to best use language models for search. Three\n",
        "broad categories of these models are dense retrieval, reranking, and RAG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf4j4OrIuOqp"
      },
      "source": [
        "# Dense Retrieval Example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1YT-JnufAbR"
      },
      "source": [
        "Dense retrieval systems rely on the concept of embeddings, the same concept\n",
        "we’ve encountered in the previous chapters, and turn the search problem into\n",
        "retrieving the nearest neighbors of the search query (after both the query and\n",
        "the documents are converted into embeddings). Figure 8-1 shows how dense\n",
        "retrieval takes a search query, consults its archive of texts, and outputs a set of\n",
        "relevant results.\n",
        "\n",
        "Let’s take a look at a dense retrieval example by using Cohere to search the Wikipedia\n",
        "page for the film Interstellar. In this example, we will do the following:\n",
        "1. Get the text we want to make searchable and apply some light processing to\n",
        "chunk it into sentences.\n",
        "2. Embed the sentences.\n",
        "3. Build the search index.\n",
        "4. Search and see the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc4GPi92uRJW"
      },
      "source": [
        "## 1. Getting the text archive and chunking it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wDrS_FkTtc4r"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cohere\n",
        "\n",
        "# Paste your API key here. Remember to not share publicly\n",
        "api_key = ''\n",
        "\n",
        "# Create and retrieve a Cohere API key from os.cohere.ai\n",
        "co = cohere.Client(api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4zCoYLMTu7XL"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
        "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
        "Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
        "\n",
        "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.\n",
        "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
        "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.\n",
        "Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
        "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.\n",
        "\n",
        "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
        "In the United States, it was first released on film stock, expanding to venues using digital projectors.\n",
        "The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.\n",
        "It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.\n",
        "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.\n",
        "Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades\"\"\"\n",
        "\n",
        "# Split into a list of sentences\n",
        "texts = text.split('.')\n",
        "\n",
        "# Clean up to remove empty spaces and new lines\n",
        "texts = [t.strip(' \\n') for t in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan',\n",
              " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine',\n",
              " 'Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind',\n",
              " 'Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007',\n",
              " 'Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar',\n",
              " 'Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm',\n",
              " 'Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles',\n",
              " 'Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects',\n",
              " 'Interstellar premiered on October 26, 2014, in Los Angeles',\n",
              " 'In the United States, it was first released on film stock, expanding to venues using digital projectors',\n",
              " 'The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014',\n",
              " 'It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight',\n",
              " 'It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics',\n",
              " 'Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time',\n",
              " 'Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Embedding the Text Chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s now embed the texts. We’ll send them to the Cohere\n",
        "API, and get back a vector for each text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the embeddings\n",
        "response = co.embed(\n",
        "  texts=texts,\n",
        "  input_type=\"search_document\",\n",
        ").embeddings\n",
        "\n",
        "embeds = np.array(response)\n",
        "print(embeds.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This outputs (15, 4096), which indicates that we have 15 vectors, each one of size\n",
        "4,096."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Building The Search Index\n",
        "Before we can search, we need to build a search index.\n",
        "An index stores the embeddings and is optimized to quickly retrieve the nearest\n",
        "neighbors even if we have a very large number of points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "dim = embeds.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.float32(embeds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Search the index\n",
        "We can now search the dataset using any query we want. We simply\n",
        "embed the query and present its embedding to the index, which will retrieve the most\n",
        "similar sentence from the Wikipedia article.\n",
        "Let’s define our search function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def search(query, number_of_results=3):\n",
        "\n",
        "  # 1. Get the query's embedding\n",
        "  query_embed = co.embed(texts=[query],\n",
        "                input_type=\"search_query\",).embeddings[0]\n",
        "\n",
        "  # 2. Retrieve the nearest neighbors\n",
        "  distances , similar_item_ids = index.search(np.float32([query_embed]), number_of_results)\n",
        "\n",
        "  # 3. Format the results\n",
        "  texts_np = np.array(texts) # Convert texts list to numpy for easier indexing\n",
        "  results = pd.DataFrame(data={'texts': texts_np[similar_item_ids[0]],\n",
        "                              'distance': distances[0]})\n",
        "\n",
        "  # 4. Print and return the results\n",
        "  print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"how precise was the science\"\n",
        "results = search(query)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| texts | distance |\n",
        "| --- | --- |\n",
        "| It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics | 10757.379883 |\n",
        "| Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar | 11566.131836 |\n",
        "| Interstellar uses extensive practical and mini... | 11922.833008 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first result has the least distance, and so is the most similar to the query. Looking\n",
        "at it, it answers the question perfectly. Notice that this wouldn’t have been possible if\n",
        "we were only doing keyword search because the top result did not include the same\n",
        "keywords in the query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Disadvantages of Dense Retrieval\n",
        "\n",
        "#### 1. Irrelevant Results When the Answer Is Missing\n",
        "- If the retrieved texts do not contain the answer, dense retrieval still returns results based on similarity scores.\n",
        "- **Example**: A query like *\"What is the mass of the moon?\"* might return unrelated results about movies or cinematography.\n",
        "- This happens because dense retrieval is based on embeddings and similarity, not direct keyword matching.\n",
        "\n",
        "#### 2. Handling Long Texts (Chunking Challenges)\n",
        "- **Transformer models have a limited context size**, restricting the number of tokens they can process at once.\n",
        "- Long documents need to be split into smaller chunks, but how this is done affects retrieval quality.\n",
        "\n",
        "##### Chunking Strategies:\n",
        "- **One Vector per Document:**\n",
        "  - Embedding only a representative part (e.g., title or introduction) leaves out a lot of information.\n",
        "  - Averaging embeddings from multiple chunks compresses information, reducing accuracy.\n",
        "- **Multiple Vectors per Document:**\n",
        "  - Documents are split into smaller chunks, and each chunk is embedded separately.\n",
        "  - This improves retrieval accuracy but increases storage and computational requirements.\n",
        "\n",
        "##### Best Practices for Chunking:\n",
        "- **Sentence-level chunks**: Too granular, losing context.\n",
        "- **Paragraph-level chunks**: Works well if paragraphs are concise.\n",
        "- **Overlapping chunks**: Improves context retention by including nearby text.\n",
        "- **Adding titles or surrounding text**: Helps provide better contextual understanding.\n",
        "\n",
        "As the field advances, more dynamic and LLM-based chunking methods are expected to emerge.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A reranker takes in the search query and a number of search results, and returns\n",
        "the optimal ordering of these documents so the most relevant ones to the query are\n",
        "higher in ranking. Cohere’s Rerank endpoint is a simple way to start using a first\n",
        "reranker. We simply pass it the query and texts and get the results back. We don’t\n",
        "need to train or tune it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"how precise was the science\"\n",
        "results = co.rerank(query=query, documents=texts, top_n=3, return_documents=True)\n",
        "results.results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for idx, result in enumerate(results.results):\n",
        "    print(idx, result.relevance_score , result.document.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "0 0.1698185 It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics\n",
        "\n",
        "1 0.07004896 The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014\n",
        "\n",
        "2 0.0043994132 Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Difference Between Dense Retrieval and Reranking\n",
        "\n",
        "| Feature         | **Dense Retrieval** | **Reranking** |\n",
        "|---------------|-----------------|----------------|\n",
        "| **Purpose** | Retrieves the most relevant documents from a large corpus. | Reorders the retrieved documents to improve ranking accuracy. |\n",
        "| **Process** | Uses vector embeddings and similarity search to retrieve top-k candidates. | Takes the top-k retrieved documents and refines their ranking based on a more sophisticated scoring model. |\n",
        "| **Speed** | Fast, optimized for large-scale retrieval. | Slower, as it applies a second-stage ranking process. |\n",
        "| **Computational Cost** | Lower, as it relies on approximate nearest neighbor (ANN) search. | Higher, as it often uses transformer models or deep learning for precise ranking. |\n",
        "| **Model Type** | Typically based on **bi-encoder** architectures (e.g., SBERT, DPR). | Often uses **cross-encoder** architectures (e.g., BERT-based rerankers). |\n",
        "| **Strengths** | Efficient for large document collections; good for first-stage retrieval. | Improves precision by considering fine-grained contextual relationships between query and documents. |\n",
        "| **Weaknesses** | May retrieve irrelevant results if the embedding similarity is misleading. | Computationally expensive and requires processing each query-document pair separately. |\n",
        "| **Example Use Case** | Finding a set of potentially relevant articles for a query. | Refining the ranking of retrieved articles to show the most relevant ones at the top. |\n",
        "\n",
        "#### How They Work Together\n",
        "1. **Dense Retrieval (First Stage)**: Quickly retrieves the top-k most relevant documents using embeddings.\n",
        "2. **Reranking (Second Stage)**: Uses a more detailed model to reorder these documents for better relevance.\n",
        "\n",
        "This two-step approach balances **efficiency** (dense retrieval) and **accuracy** (reranking), making it a common pipeline in information retrieval systems. 🚀\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieval-Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A basic RAG pipeline is made up of a search step followed by a grounded\n",
        "generation step where the LLM is prompted with the question and the information\n",
        "retrieved from the search step.\n",
        "\n",
        "RAG systems incorporate search capabilities in addition to generation capabilities.\n",
        "They can be seen as an improvement to generation systems because they reduce\n",
        "their hallucinations and improve their factuality. They also enable use cases of “chat\n",
        "with my data” that consumers and companies can use to ground an LLM on internal\n",
        "company data, or a specific data source of interest (e.g., chatting with a book).\n",
        "This also extends to search systems. More search engines are incorporating an LLM\n",
        "to summarize results or answer questions submitted to the search engine. Examples\n",
        "include Perplexity, Microsoft Bing AI, and Google Gemini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Example: RAG with Local Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-10 19:37:43--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 2600:9000:225f:ac00:17:b174:6d00:93a1, 2600:9000:225f:4600:17:b174:6d00:93a1, 2600:9000:225f:6800:17:b174:6d00:93a1, ...\n",
            "Connecting to huggingface.co (huggingface.co)|2600:9000:225f:ac00:17:b174:6d00:93a1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/8a83c7fb9049a9b2e92266fa7ad04933bb53aa1e85136b7b30f1b8000ff2edef?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-q4.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-q4.gguf%22%3B&Expires=1741635464&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTYzNTQ2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvOGE4M2M3ZmI5MDQ5YTliMmU5MjI2NmZhN2FkMDQ5MzNiYjUzYWExZTg1MTM2YjdiMzBmMWI4MDAwZmYyZWRlZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=XWSoYDhAv-VkpSFzuvJ%7E7Jb3cK%7E1DDzk5dFCVMMG5GYFt7JFbrj5uQHciCTsrF862qEVfYPvWpAkZmDpz-46oN5TsEtG3VBlCi5ya0XR1FkvN0u0MYRYCzQz1NZ7lMJqkKWF7i2NZCf9kOO08QooUHZJ-zuw8eQ5%7EL-H3lXVPuTRiIa3ZWHc0n28vG%7E8GYK6Y86gnez4WhzzBunLvQaAkI5M5Ge6oCCjx-oN%7ELy-A1Y9w2BogRu3CEAVSdlmfBLLChfDib2eESgAYkMYj-9jv9UhvoJgHXOHDTLTotaONeWMKiEDouo02nVUjvs-fkqOuW4pkoEQuBmbqp-vzH1IiQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-03-10 19:37:44--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/8a83c7fb9049a9b2e92266fa7ad04933bb53aa1e85136b7b30f1b8000ff2edef?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-q4.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-q4.gguf%22%3B&Expires=1741635464&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTYzNTQ2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvOGE4M2M3ZmI5MDQ5YTliMmU5MjI2NmZhN2FkMDQ5MzNiYjUzYWExZTg1MTM2YjdiMzBmMWI4MDAwZmYyZWRlZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=XWSoYDhAv-VkpSFzuvJ%7E7Jb3cK%7E1DDzk5dFCVMMG5GYFt7JFbrj5uQHciCTsrF862qEVfYPvWpAkZmDpz-46oN5TsEtG3VBlCi5ya0XR1FkvN0u0MYRYCzQz1NZ7lMJqkKWF7i2NZCf9kOO08QooUHZJ-zuw8eQ5%7EL-H3lXVPuTRiIa3ZWHc0n28vG%7E8GYK6Y86gnez4WhzzBunLvQaAkI5M5Ge6oCCjx-oN%7ELy-A1Y9w2BogRu3CEAVSdlmfBLLChfDib2eESgAYkMYj-9jv9UhvoJgHXOHDTLTotaONeWMKiEDouo02nVUjvs-fkqOuW4pkoEQuBmbqp-vzH1IiQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.66.2.2, 18.66.2.74, 18.66.2.98, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.66.2.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2393231072 (2.2G) [binary/octet-stream]\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-q4.gguf’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   2.23G  7.06MB/s    in 6m 8s   \n",
            "\n",
            "2025-03-10 19:43:52 (6.20 MB/s) - ‘Phi-3-mini-4k-instruct-q4.gguf’ saved [2393231072/2393231072]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the generation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using llama.cpp, llama-cpp-python, and LangChain, we load the text generation\n",
        "model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n",
            "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 8 CPU cores\n"
          ]
        }
      ],
      "source": [
        "from langchain import LlamaCpp\n",
        "import multiprocessing\n",
        "\n",
        "# Ensure your model file is CPU-compatible (q4, q5 quantized models recommended)\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",  # Ensure you're using a CPU-friendly model\n",
        "    n_gpu_layers=0,  # Force CPU execution (prevents Metal GPU issues)\n",
        "    n_batch=256,  # Optimize batch size for CPU performance\n",
        "    n_threads=multiprocessing.cpu_count(),  # Use all available CPU cores\n",
        "    max_tokens=500,\n",
        "    n_ctx=2048,  # Reduce context size if memory issues occur\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Check available CPU cores\n",
        "print(f\"Using {multiprocessing.cpu_count()} CPU cores\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Embedding Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_32391/1728599694.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(\n",
            "/Users/aybikealkan/.pyenv/versions/3.10.6/envs/hands-on_llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Embedding Model for converting text to numerical representations\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name='BAAI/bge-small-en-v1.5'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='BAAI/bge-small-en-v1.5', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing the Vector Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Create a local vector database\n",
        "db = FAISS.from_texts(texts, embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan',\n",
              " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine',\n",
              " 'Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind',\n",
              " 'Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007',\n",
              " 'Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar',\n",
              " 'Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm',\n",
              " 'Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles',\n",
              " 'Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects',\n",
              " 'Interstellar premiered on October 26, 2014, in Los Angeles',\n",
              " 'In the United States, it was first released on film stock, expanding to venues using digital projectors',\n",
              " 'The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014',\n",
              " 'It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight',\n",
              " 'It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics',\n",
              " 'Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time',\n",
              " 'Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The RAG prompt\n",
        "A prompt template plays a vital part in the RAG pipeline. It is the central place where\n",
        "we communicate the relevant documents to the LLM. To do so, we will create an\n",
        "additional input variable named context that can provide the LLM with the retrieved\n",
        "documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "# Create a prompt template\n",
        "template = \"\"\"<|user|>\n",
        "Relevant information:\n",
        "{context}\n",
        "\n",
        "Provide a concise answer the following question using the relevant information provided above:\n",
        "{question}<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# RAG Pipeline\n",
        "rag = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type='stuff',\n",
        "    retriever=db.as_retriever(),\n",
        "    chain_type_kwargs={\n",
        "        \"prompt\": prompt\n",
        "    },\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'Income generated',\n",
              " 'result': ' The information provided does not directly address the income generated from \"Interstellar.\" However, we can infer that the collaboration of notable figures like Kip Thorne and companies such as Double Negative, along with its use of high-quality equipment like 35 mm movie film in Panavision anamorphic format and IMAX 70mm, contributed to the production\\'s potential success. For specific financial details, additional information outside of this context would be required.'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag.invoke('Income generated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'worldwide gross',\n",
              " 'result': ' The worldwide gross of Interstellar was over $677 million, making it the tenth-highest grossing film of 2014.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag.invoke('worldwide gross')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'is the movie scientifically trustable',\n",
              " 'result': ' Yes, Interstellar is considered to be scientifically trustable as it has received praise from many astronomers for its accurate portrayal of theoretical astrophysics and is regarded by sci-fi experts as one of the best science fiction films of all time.'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag.invoke('is the movie scientifically trustable')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'f5712b18-5792-47a2-bd47-43128b979f42': Document(id='f5712b18-5792-47a2-bd47-43128b979f42', metadata={}, page_content='Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan'), '1325b284-31f4-4926-95be-29365b60555a': Document(id='1325b284-31f4-4926-95be-29365b60555a', metadata={}, page_content='It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine'), 'f258f984-2a91-4389-8b2e-020689cfa508': Document(id='f258f984-2a91-4389-8b2e-020689cfa508', metadata={}, page_content='Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind'), '41b402a0-b8c4-4480-9e00-53214e599124': Document(id='41b402a0-b8c4-4480-9e00-53214e599124', metadata={}, page_content='Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007'), '90b3c2c7-ca7a-4f5c-88f6-0efe5cb6a38d': Document(id='90b3c2c7-ca7a-4f5c-88f6-0efe5cb6a38d', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'), '8fcf0309-4552-42c0-9ddb-a02402930a2b': Document(id='8fcf0309-4552-42c0-9ddb-a02402930a2b', metadata={}, page_content='Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm'), '75066690-7f09-457f-a403-235cfb96e180': Document(id='75066690-7f09-457f-a403-235cfb96e180', metadata={}, page_content='Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles'), 'e8ad169f-0743-453d-8790-06e85596e1a4': Document(id='e8ad169f-0743-453d-8790-06e85596e1a4', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'), 'e323fcc3-e8e3-4dec-abff-32884b92492a': Document(id='e323fcc3-e8e3-4dec-abff-32884b92492a', metadata={}, page_content='Interstellar premiered on October 26, 2014, in Los Angeles'), '4d75b3ce-e4ad-4ef7-89cb-2368e5e63e3f': Document(id='4d75b3ce-e4ad-4ef7-89cb-2368e5e63e3f', metadata={}, page_content='In the United States, it was first released on film stock, expanding to venues using digital projectors'), 'b0895a92-e08c-451f-8c69-289df3dc6b13': Document(id='b0895a92-e08c-451f-8c69-289df3dc6b13', metadata={}, page_content='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'), 'e79fdc17-4484-49a3-b5bc-8290cd7c0fe1': Document(id='e79fdc17-4484-49a3-b5bc-8290cd7c0fe1', metadata={}, page_content='It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight'), '6f85a2ac-4ffd-43b0-8c55-549f66f2c482': Document(id='6f85a2ac-4ffd-43b0-8c55-549f66f2c482', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'), 'b1a582b1-986c-4548-b7b4-f062a3c992e1': Document(id='b1a582b1-986c-4548-b7b4-f062a3c992e1', metadata={}, page_content='Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time'), 'e34848e4-ac48-4711-b8c6-fb8283fa8d54': Document(id='e34848e4-ac48-4711-b8c6-fb8283fa8d54', metadata={}, page_content='Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades')}\n"
          ]
        }
      ],
      "source": [
        "print(db.docstore._dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of stored vectors: (15, 384)\n",
            "Sample vector: [ 9.00124945e-03 -1.84804648e-02 -7.19212964e-02 -3.18553322e-03\n",
            "  1.87151860e-02 -3.19610424e-02 -3.68364947e-03 -1.89144518e-02\n",
            "  2.25169566e-02 -3.31748873e-02  8.86677578e-02 -5.94718046e-02\n",
            " -1.13017736e-02  3.32215764e-02 -4.97691743e-02  8.32819007e-03\n",
            "  8.12381413e-03 -2.57822964e-02 -4.16799448e-02  4.70038392e-02\n",
            " -2.46361103e-02  1.39289545e-02  4.51603308e-02 -5.17833792e-02\n",
            " -1.02366330e-02  7.20374510e-02 -3.23839635e-02 -2.94736810e-02\n",
            " -8.58287737e-02 -1.28986612e-01  5.47142364e-02  3.67259770e-03\n",
            "  8.90053716e-03  1.19207455e-02  1.51587185e-02 -6.56802952e-02\n",
            " -2.69270875e-02 -1.49785150e-02 -2.40695383e-02 -5.39990049e-03\n",
            " -6.64924039e-03 -2.08047908e-02  1.00863911e-02 -1.98865198e-02\n",
            " -6.92458823e-03  1.48276323e-02 -2.29625590e-02 -1.87566224e-02\n",
            "  4.01440449e-02 -4.84026372e-02  5.38560152e-02 -1.17137298e-01\n",
            " -2.16658972e-02 -7.19817029e-03 -9.19066146e-02  7.47764334e-02\n",
            " -1.60866268e-02  4.84245643e-02  4.27504480e-02 -4.60331813e-02\n",
            "  5.05440077e-03  4.87346854e-03 -1.30717382e-01  4.84596901e-02\n",
            "  9.05681774e-02  7.96527565e-02 -6.39619231e-02 -8.55366141e-02\n",
            " -6.25998992e-03 -4.27375101e-02 -1.13980351e-02  1.85788386e-02\n",
            "  4.84614037e-02  8.23639408e-02  5.71693815e-02  1.72842294e-02\n",
            "  2.83452924e-02 -4.66917865e-02 -4.27209847e-02  7.91156664e-04\n",
            "  8.68168026e-02  8.59820005e-03 -1.07881084e-01  4.19526510e-02\n",
            " -5.10643311e-02  4.64364775e-02  1.06619140e-02  3.31462547e-02\n",
            "  6.00783639e-02  2.63578035e-02 -3.02053038e-02  5.18678920e-04\n",
            " -3.41177247e-02  4.83571040e-03 -8.46564323e-02 -3.38108353e-02\n",
            "  7.63801336e-02 -4.52053845e-02 -3.93222682e-02  2.82783777e-01\n",
            "  5.24107814e-02 -7.30009973e-02  3.86584103e-02  1.13653811e-02\n",
            " -2.79169660e-02  3.11934724e-02  2.62299143e-02  5.49843023e-03\n",
            "  6.51099458e-02  4.94109318e-02  2.17178687e-02  8.16372037e-03\n",
            "  1.22393826e-02 -3.38398740e-02  4.81197909e-02  1.14694359e-02\n",
            "  6.31756261e-02 -3.54327373e-02  6.04458200e-03 -4.87406850e-02\n",
            " -2.81483773e-02 -4.00009453e-02 -1.40403416e-02 -3.68131064e-02\n",
            " -7.89066181e-02 -4.45963629e-02  5.19242622e-02  4.72633801e-02\n",
            " -5.48103033e-03 -5.42601123e-02  3.04045286e-02  3.79900075e-02\n",
            " -5.38660139e-02  3.23726609e-02 -2.43987404e-02  3.63293327e-02\n",
            " -2.77193021e-02 -2.20683590e-02  7.04615191e-03 -8.75102449e-03\n",
            "  2.70913495e-03 -1.81481224e-02 -5.03680557e-02 -7.42645562e-03\n",
            "  6.66085109e-02 -6.79030195e-02 -4.74110618e-03  4.80102226e-02\n",
            " -1.67480465e-02  5.74376471e-02  2.79704481e-02 -1.81418583e-02\n",
            " -5.05608991e-02  2.63412297e-02  2.82844547e-02 -2.00612210e-02\n",
            "  1.01761438e-01  1.55774243e-02  2.06601503e-03  5.91681004e-02\n",
            " -5.48385344e-02 -3.06960735e-02 -4.33144309e-02  1.26063913e-01\n",
            " -3.60250585e-02 -7.62415156e-02  8.09301622e-03  5.54444678e-02\n",
            "  4.81355935e-02  2.76134517e-02 -1.20427040e-02 -1.15848202e-02\n",
            " -1.72259454e-02 -2.66171657e-02  3.22907455e-02 -1.95025802e-02\n",
            " -8.29822421e-02  7.90146459e-03  4.29854076e-03  6.99589252e-02\n",
            "  3.35164517e-02 -1.28080733e-02  2.90937081e-04  5.73886707e-02\n",
            "  2.26692688e-02 -6.47302940e-02  1.13282744e-02 -4.28265296e-02\n",
            " -6.71362225e-03  1.71776880e-02 -1.61286015e-02  1.19516395e-01\n",
            "  7.48494267e-03  7.90300891e-02  3.94885130e-02 -1.70670506e-02\n",
            " -1.00878948e-04  3.91186439e-02 -6.31580576e-02 -1.35143315e-02\n",
            " -2.35361140e-02 -1.41893020e-02 -4.62749600e-02  5.08851819e-02\n",
            " -5.11268228e-02  2.38178042e-03 -5.46208955e-02  5.64731546e-02\n",
            " -4.05289419e-02  5.13587333e-03 -3.64879519e-02  9.49569396e-04\n",
            "  3.19651105e-02  3.44865061e-02 -7.25709796e-02  3.46600078e-02\n",
            "  2.99257692e-02 -1.68270227e-02 -1.60850193e-02 -1.69550963e-02\n",
            " -1.34442262e-02 -5.63925914e-02 -1.48756262e-02 -2.61251360e-01\n",
            "  1.61110517e-02 -5.25570028e-02 -8.92525911e-02  6.81228936e-03\n",
            "  2.74983533e-02  4.69787195e-02  9.37686022e-03  3.58924940e-02\n",
            "  4.84433621e-02  3.63651849e-02  4.17950861e-02 -1.79303158e-02\n",
            " -3.36757302e-02 -1.70839876e-02 -5.11977859e-02 -1.59645863e-02\n",
            " -6.47555292e-03  2.71942783e-02 -1.47098461e-02  3.33665311e-02\n",
            " -1.23611363e-02 -7.17875957e-02  2.01459657e-02 -8.65449086e-02\n",
            " -2.53613871e-02  1.73863441e-01  4.80022095e-02  1.13218032e-01\n",
            "  1.55412946e-02 -6.00640588e-02  4.38302420e-02  6.60606101e-02\n",
            " -8.85546580e-02  1.78378839e-02  7.93252233e-03  9.32453945e-02\n",
            "  1.34054916e-02 -5.89509569e-02  1.27066961e-02  1.63890962e-02\n",
            "  2.68549528e-02  1.41184600e-02 -2.29289737e-02  2.01972649e-02\n",
            "  3.32511142e-02 -4.48486134e-02  3.83293927e-02  2.74978462e-03\n",
            " -5.34512755e-03 -1.33567750e-02 -6.08444680e-03 -2.59023644e-02\n",
            " -7.50210881e-02 -4.96285744e-02  2.33497899e-02 -3.42620946e-02\n",
            "  7.43800588e-03 -5.02515305e-03  4.50522639e-02 -7.47408206e-03\n",
            "  4.15734611e-02 -2.92116497e-02  5.47123924e-02  3.35787274e-02\n",
            " -1.04866130e-02 -1.36562986e-02 -1.97444521e-02 -3.38025801e-02\n",
            " -4.41813655e-02 -1.96640398e-02  3.79280448e-02 -5.09901866e-02\n",
            " -5.65498620e-02  9.45117921e-02  4.11985582e-03  7.20750615e-02\n",
            "  4.24365997e-02  1.07927378e-02 -1.39108561e-02  4.63894457e-02\n",
            "  7.79351294e-02  1.18726511e-02 -2.43817437e-02 -1.64847709e-02\n",
            "  3.20633352e-02 -5.60884411e-03 -3.36974338e-02 -5.44726253e-02\n",
            " -6.04959726e-02  3.81047614e-02  2.65702475e-02  8.84761102e-03\n",
            " -1.80391390e-02 -2.13860273e-02  6.60436228e-03 -2.03820825e-01\n",
            "  2.79160845e-03 -2.06447523e-02  1.93561018e-02  2.74427794e-02\n",
            " -7.24650174e-02 -5.46888001e-02  1.10752232e-01  5.43045625e-02\n",
            " -1.28756724e-02  2.34855898e-02  9.16830380e-04 -7.60197714e-02\n",
            "  7.10510463e-02  1.72387213e-02  4.37214300e-02  3.85236852e-02\n",
            "  1.54182920e-02 -7.13577075e-03  3.59953642e-02 -1.27974236e-02\n",
            " -1.71147212e-02  1.67999744e-01 -2.10244171e-02 -3.27265114e-02\n",
            " -1.57910436e-02  6.11235052e-02  8.06491673e-02  7.21213222e-03\n",
            "  2.17028335e-02  5.97553933e-03  3.53715941e-02  9.97224264e-03\n",
            " -2.74211615e-02 -3.51828635e-02  3.66403759e-02  1.40361274e-02\n",
            "  5.27026057e-02  2.47339606e-02  1.03268139e-02  4.91818180e-03\n",
            "  7.06964545e-03  5.01169302e-02 -1.39159277e-01  5.79068549e-02\n",
            "  4.09692228e-02 -5.33930073e-03  6.02966622e-02 -1.03353374e-01\n",
            " -1.81984846e-02 -1.24792874e-01 -3.13795987e-03  3.48997600e-02\n",
            "  6.43785819e-02 -1.29502323e-02  1.58273969e-02 -1.05935540e-02\n",
            " -3.06291096e-02 -1.88229904e-02 -4.80699632e-03 -1.68484002e-02\n",
            " -1.82440877e-02 -6.76103532e-02  3.96042988e-02  3.01720910e-02]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the FAISS index object\n",
        "faiss_index = db.index\n",
        "\n",
        "# Get all stored vectors\n",
        "vectors = np.array([faiss_index.reconstruct(i) for i in range(faiss_index.ntotal)])\n",
        "\n",
        "print(\"Shape of stored vectors:\", vectors.shape)  # (num_texts, embedding_dim)\n",
        "print(\"Sample vector:\", vectors[0])  # Print the first stored vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hands-on_llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
